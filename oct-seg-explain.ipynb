{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Kugelman et al 2019 Code\n",
    "## Data for this Jupyter notebook\n",
    "These files need to be in the same directory as this jupyter notebook:\n",
    "\n",
    "1. LI = Lab images (Aconitums.)\n",
    "2. KEX = (Kugelman et al 2009) example_data.hdf5\n",
    "\n",
    "## Semantic Model\n",
    "The code in https://github.com/jakugel/oct-choroid-seg will be analyzed and modified to read in area segmentations instead of boundaries, and to decide whether to use hdf5 format for the images or read the images directly from a directory.\n",
    "\n",
    "The boundaries are the ILM, RPE and CSI. For the semantic segmentation these 4 regions (areas) are needed:\n",
    "\n",
    "1. Vitreous (top of the image to ILM)\n",
    "2. Retinal (ILM to RPE)\n",
    "3. Choroid (RPE to CHR)\n",
    "4. Sclera (CHR to bottom of the image)\n",
    "\n",
    "## Loading Area Labels\n",
    "The semantic model requires image area segmentations, but the functions `load_training_data` and `load_validation_data` in `train_script_semantic_general.py` are written for segmentation files that contain boundaries.\n",
    "\n",
    "These boundaries are then converted to areas or “masks” in function `create_all_area_masks(images, segs)`.\n",
    "\n",
    "If the input training labels are already area labels, the function `create_all_area_masks` does not need to convert boundaries to areas. It should be enough to set `mask = segs`.\n",
    "\n",
    "## Dependencies\n",
    "See ReadMe.md\n",
    "\n",
    "# Understanding the Images\n",
    "## Directory structure and HDF5 structure\n",
    "LI = Lab images\n",
    "KEX = (Kugelman et al 2009) example_data.hdf5\n",
    "\n",
    "The KEX file can be read with hdf52images.py and has this structure:\n",
    "\n",
    "test_images\n",
    "Dims: (3, 1536, 496, 1)\n",
    "test_segs\n",
    "Dims: (3, 3, 1536)\n",
    "train_images\n",
    "Dims: (3, 1536, 496, 1)\n",
    "train_segs\n",
    "Dims: (3, 3, 1536)\n",
    "val_images\n",
    "Dims: (3, 1536, 496, 1)\n",
    "val_segs\n",
    "Dims: (3, 3, 1536)\n",
    "\n",
    "The 4 dimensions (called 'shape' in hdf5 format) of the images are :\n",
    "\n",
    "num_images = images.shape[0]\n",
    "image_width = images.shape[1]\n",
    "image_height = images.shape[2]\n",
    "num_channels = images.shape[3]\n",
    "\n",
    "The remlmaterials directory uses the same structure, and the LI images are read from the directory not an hdf5 file.\n",
    "\n",
    "The format is:\n",
    "\n",
    "val_images\n",
    "3 tif files: (496, 1536)\n",
    "val_segs\n",
    "3 png files: (496, 1536)\n",
    "... same for test and train datasets.\n",
    "\n",
    "Differences with example_data.hdf5\n",
    "KEX images need to be rotated -90 or + 270 degrees to be in the same angle as RGLI\n",
    "LI use RGB colors and need to be converted to greyscale\n",
    "LI image format is hdf5, KEX is TIF for the images and png for the segmentations/labels\n",
    "KEX uses boundaries as labels, RGI uses areas\n",
    "LI has scanning instrument label on the images\n",
    "KEX accounts for RGB or greyscale with the 4th dimension of \"channels\"\n",
    "Code Incompatibilities\n",
    "The (Kugelman et al 2009) code makes extensive use of the hdf5 format. Some functions, such as ImageDatabase in image_database.py expect hdf5 datasets as arguments.\n",
    "\n",
    "The code below converts a numpy array to an hdf5 dataset, but requires the creation of an hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# load image as is\n",
    "image = np.array(Image.open('Aconitums004.tif'))\n",
    "h5f = h5py.File('data.h5', 'w')\n",
    "try:\n",
    "    h5imgarray=h5f.create_dataset('train_images', data=image)\n",
    "    print(\"\\nLI\")\n",
    "    # The code below outputs the same dimenions as print(\"Dims: \" + str(dset.shape))\n",
    "    # But clarifies the hdf5 dataset structure\n",
    "    for i in range(h5imgarray.ndim):\n",
    "        print(h5imgarray.shape[i])\n",
    "finally:\n",
    "    h5f.close()\n",
    "\n",
    "#load KEX images\n",
    "h5f = h5py.File('example_data.hdf5', 'r')\n",
    "try:\n",
    "    h5=h5f['train_images'][:]\n",
    "    print(\"\\nKEX\")\n",
    "    for i in range(h5.ndim):\n",
    "        print(h5.shape[i])\n",
    "finally:    \n",
    "    h5f.close()\n",
    "\n",
    "#Modify LI to the same format as KEX\n",
    "train_images = []\n",
    "# Convert to greyscale and rotat\n",
    "train_images.append(np.rot90(np.array(ImageOps.grayscale(Image.open('Aconitums002.tif'))),3))\n",
    "train_images.append(np.rot90(np.array(ImageOps.grayscale(Image.open('Aconitums003.tif'))),3))\n",
    "train_images.append(np.rot90(np.array(ImageOps.grayscale(Image.open('Aconitums004.tif'))),3))\n",
    "# Add the 4th axis with dimension 1 \n",
    "train_images=np.asarray(train_images)\n",
    "train_images=train_images.reshape(3, 1536,496,1)\n",
    "h5f = h5py.File('data.h5', 'w')\n",
    "try:\n",
    "    h5imgarray=h5f.create_dataset('train_images', data=train_images)\n",
    "    print(\"\\nLI Reformatted\")\n",
    "    for i in range(h5imgarray.ndim):\n",
    "        print(h5imgarray.shape[i])\n",
    "\n",
    "finally:\n",
    "    h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Code Modifications\n",
    "## Dependencies\n",
    "`environment.yml`\n",
    "\n",
    "## Processing images\n",
    "`create_all_area_masks(images, segs)` calls `create_area_mask(image, segs)` for all training or evaluation image and label pairs. In our dataset, images are TIF files, and segs are PNG files.\n",
    "\n",
    "The images, segs parameters of `create_all_area_masks` are HDF5 datasets, not regular arrays. The return value is an np.array.\n",
    "\n",
    "We modify `create_area_mask(image, segs)` to set `mask = segs` **if the image and segs dimensions and dtype are the same and dtype is uint8.**\n",
    "\n",
    "*Warning: Matplolib reads png files with function png.read_png_float by default which makes it seem integer png files are of type float32. Use PIL instead.*\n",
    "\n",
    "The code below uses PIL to inspect the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "\n",
    "def create_area_mask(image, segs):\n",
    "    mk = np.array([])    \n",
    "    #verify image & segs have the same integer dimensions\n",
    "    if image.shape == segs.shape and segs.dtype == image.dtype and np.issubdtype(np.uint8,segs.dtype) :\n",
    "        mk = segs\n",
    "    \n",
    "    return mk\n",
    "\n",
    "# load image as pixel array\n",
    "image = np.array(Image.open('Aconitums004.tif'))\n",
    "\n",
    "# Verify image is correct: summarize shape of the pixel array\n",
    "print(image.dtype)\n",
    "print(image.shape)\n",
    "\n",
    "# Verify image is correct: display the array of pixels as an image\n",
    "\n",
    "pyplot.imshow(image)\n",
    "pyplot.show()\n",
    "\n",
    "# load image as pixel array\n",
    "# Be aware that matplotlib uses by default png.read_png_float for png images, \n",
    "# use PIL instead:\n",
    "segs = np.array(Image.open('Aconitums004.png'))\n",
    "\n",
    "\n",
    "\n",
    "mask = create_area_mask(image, segs)\n",
    "if mask.all():\n",
    "  print(\"Mask is empty\")\n",
    "else:\n",
    "    # Verify mask is correct: summarize shape of the pixel array\n",
    "    print(mask.dtype)\n",
    "    print(mask.shape)\n",
    "\n",
    "    # Verify mask is correct: display the array of pixels as an image\n",
    "\n",
    "    pyplot.imshow(mask)\n",
    "    pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
